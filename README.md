# Tensorflow_practice
This repository hold all my codes which are helpful for completing tensorflow certificates and understanding basic application of deep learning models. 

# German_Signs/german_classification (CNN)

It is one of the questions which is  used in image classification where the dataset has 43 classes of labeled data and all the labels are in categorical mode with the image size of (30,30).

# Prophet forecasting model (Time series question)

This is not a general example of tensorflow practicing model but it helps in understanding & enhancing forecasting. Prophet is a forecasting model which is developed by using the fourier series, it has the ability to forecast the patterns by accepting the seasonality, trend and also holiday goals. one of its most used applications is calculating or analyzing and setting goals. It uses additive method of analyzing seasonals. In the provided code I have utilized LT meter data which has time frame along the voltage currents which is time series data.

# BEANS (CNN) 

classification with images between categories of beans using the beans dataset. The data has three classes.


# Electrical house prediction/household_power (Time series question) 

This question is trained on the dataset which consists measurements of electrical power consumption in one household with a data granularity of minutes over a duration of 4 years. 
 

# Hurricane (image classification with CNN) 

we need to built a classifier using dataset obtained from satellite images of hurricane. The dataset only has two labels hence sigmoid function can help because sigmoid function only releases either 0 or 1, hence it is either damaged or not-damaged.

# Rock_paper_scissors (image classification with CNN)

as the game as suggests rock,paper and scissors have 3 class labels, hence the last neural network has to have 3 units and SoftMax helps in identifying the image.

# sarcasm ( NLP ) 
 
it is one of the most interesting question of tensorflow course, here unlike dealing with categorical or numerical data we utilize texts with the help of text tokenizer, and the objective of the model to detect whether in the test case has sarcasm or not. This function can help make a difference in various segments of NLP if trained using benchmark.
